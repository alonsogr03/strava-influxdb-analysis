---
title: "Práctica Final. Memoria de Consultas sobre Datos de Strava en InfluxDB"
author:
  - Alba Martínez de la Hermosa
  - Alonso González Romero
date: today
format:
  html:
    page-layout: full  
    css: style.css
    embed-resources: true
    plotly-connected: true
    toc: true
    toc-depth: 3
    number-sections: true
lang: es
abstract: |
  En esta memoria se documentan las consultas realizadas sobre los datos de actividades de Strava, almacenados en una base de datos InfluxDB. Se incluyen descripciones de las consultas, el código utilizado, los resultados obtenidos y visualizaciones relevantes.
---

# Introducción

En el contexto actual del análisis deportivo, la capacidad de centralizar, procesar y explotar datos biométricos y de posicionamiento es fundamental para evaluar el rendimiento. Este proyecto tiene como objetivo principal la creación de una arquitectura de datos escalable para el almacenamiento y análisis de actividades deportivas de carrera.

El proyecto aborda la problemática de la dispersión de datos en plataformas de terceros (como Strava) mediante la implementación de un proceso **ETL (Extract, Transform, Load)** propio. Hemos diseñado un sistema que permite a dos usuarios diferentes (Alba y Alonso) extraer sus actividades con granulaidad de segundo (series temporales), normalizarlas y almacenarlas en una base de datos **InfluxDB**. Esto nos permite superar las limitaciones de análisis de las aplicaciones comerciales y realizar consultas personalizadas sobre variables críticas como la frecuencia cardíaca, la potencia estimada, la velocidad y la pendiente.

# Arquitectura del Sistema y Proceso ETL

## Extracción de Datos desde la API de Strava

El proceso de extracción de datos comienza con la autenticación en la **API de Strava** mediante el protocolo OAuth 2.0. Para ello, cada usuario (Alba y Alonso) dispone de credenciales únicas almacenadas de forma segura en un archivo `.env` (no versionado en el repositorio). Este archivo contiene:

- **Client ID**: Identificador de la aplicación registrada en Strava
- **Client Secret**: Clave secreta de la aplicación
- **Refresh Token**: Token de larga duración que permite obtener access tokens sin intervención manual

El script principal (`main.py`) utiliza la librería `python-dotenv` para cargar estas variables de entorno de forma segura, evitando hardcodear credenciales sensibles en el código fuente.

### Flujo de Autenticación y Obtención de Tokens

La función `obtener_token_acceso()` implementa el flujo de renovación de tokens:

1. Realiza una petición POST al endpoint `https://www.strava.com/oauth/token`
2. Envía el refresh token junto con las credenciales de la aplicación
3. Recibe un nuevo access token válido por 6 horas
4. Este access token se utiliza para todas las peticiones posteriores a la API

```python
def obtener_token_acceso(client_id, client_secret, refresh_token, usuario):
    auth_url = "https://www.strava.com/oauth/token"
    payload = {
        'client_id': client_id,
        'client_secret': client_secret,
        'refresh_token': refresh_token,
        'grant_type': 'refresh_token',
        'f': 'json'
    }
    res = requests.post(auth_url, data=payload, verify=False)
    return res.json()['access_token']
```

### Descarga de Datos de Actividades (Streams)

Una vez autenticados, utilizamos el endpoint de **streams** de Strava para obtener datos de alta granularidad (segundo a segundo) de cada actividad. La función `descargar_datos_actividad()` solicita todos los streams disponibles:

- **time**: Tiempo transcurrido desde el inicio (segundos)
- **distance**: Distancia acumulada (metros)
- **latlng**: Coordenadas GPS (latitud, longitud)
- **altitude**: Altitud (metros)
- **velocity_smooth**: Velocidad suavizada (m/s)
- **heartrate**: Frecuencia cardíaca (bpm)
- **cadence**: Cadencia de pasos o pedaladas (rpm/spm)
- **watts**: Potencia (solo si disponible)
- **temp**: Temperatura
- **grade_smooth**: Pendiente suavizada (%)

El proceso de transformación incluye:

1. **Separación de coordenadas GPS**: El stream `latlng` contiene arrays de [latitud, longitud] que se separan en columnas independientes
2. **Cálculo de timestamps absolutos**: Los valores de `time` (relativos al inicio) se convierten a timestamps absolutos sumándolos a la fecha de inicio de la actividad
3. **Creación de DataFrame**: Todos los streams se consolidan en un DataFrame de pandas

```python
# Obtener fecha de inicio de la actividad
url_act = f"https://www.strava.com/api/v3/activities/{activity_id}"
resp_act = requests.get(url_act, headers=headers).json()
start_date = datetime.strptime(resp_act['start_date'], "%Y-%m-%dT%H:%M:%SZ")

# Calcular timestamps reales
df['timestamp_real'] = df['time'].apply(lambda x: start_date + timedelta(seconds=x))
```

## Transformación y Preparación de Datos

Antes de cargar los datos en InfluxDB, se realiza una transformación crítica para enriquecer el dataset con metadatos necesarios para las consultas posteriores. La función `preparar_csv_para_influx()` añade las siguientes columnas:

- **measurement**: Tipo de actividad (Run, Cycling, Swimming) - se utilizará como nombre de la tabla en InfluxDB
- **usuario**: Identificador del atleta (Alba o Alonso)
- **id_actividad**: ID único de la actividad en Strava
- **tipo_actividad**: Clasificación de la actividad

Estas columnas se configurarán como **tags** en InfluxDB, lo que permite realizar consultas eficientes filtradas por usuario o actividad.

## Variables Disponibles en el Dataset

El dataset final contiene las siguientes variables para cada segundo de la actividad:

| Variable | Descripción | Unidad | Tipo |
|----------|-------------|--------|------|
| `timestamp_real` | Timestamp absoluto | DateTime | Field |
| `time` | Tiempo relativo desde inicio | segundos | Field |
| `distance` | Distancia acumulada | metros | Field |
| `latitude` | Latitud GPS | grados | Field |
| `longitude` | Longitud GPS | grados | Field |
| `altitude` | Altitud | metros | Field |
| `velocity_smooth` | Velocidad suavizada | m/s | Field |
| `heartrate` | Frecuencia cardíaca | bpm | Field |
| `cadence` | Cadencia | spm/rpm | Field |
| `watts` | Potencia (si disponible) | W | Field |
| `temp` | Temperatura | °C | Field |
| `grade_smooth` | Pendiente | % | Field |
| `usuario` | Identificador del usuario | - | Tag |
| `id_actividad` | ID de la actividad | - | Tag |
| `tipo_actividad` | Tipo de actividad | - | Tag |

## Carga en InfluxDB

InfluxDB es una base de datos de series temporales optimizada para datos con timestamps y alta frecuencia de escritura. Utilizamos **InfluxDB Cloud (v3)** con el cliente `influxdb_client_3`.

### Configuración de la Conexión

La conexión a InfluxDB requiere:

- **Host**: URL del servidor InfluxDB Cloud
- **Token**: Token de autenticación con permisos de escritura
- **Organización**: Nombre de la organización en InfluxDB
- **Database**: Nombre del bucket/database donde se almacenarán los datos

Todas estas credenciales se almacenan en variables de entorno por seguridad.

### Proceso de Carga

La función `subir_a_influxdb()` realiza la carga utilizando el método `write_file()`:

```python
client = InfluxDBClient3(host=host, token=token, org=org, database=database)

client.write_file(
    file=archivo_csv,
    tag_columns=["measurement", "usuario", "id_actividad", "tipo_actividad"],
    timestamp_column="timestamp_real",
    data_format="csv"
)
```

**Puntos clave del proceso:**

- Se especifican las columnas que funcionarán como **tags** (índices) para optimizar las consultas
- Se indica la columna de timestamp para el eje temporal
- El measurement (tipo de actividad) se usa como nombre de la tabla

### Ventajas de esta Arquitectura

1. **Escalabilidad**: InfluxDB está optimizado para series temporales con millones de puntos
2. **Consultas eficientes**: Los tags permiten filtrar rápidamente por usuario o actividad
3. **Downsampling**: Soporte nativo para agregaciones temporales (medias móviles, resúmenes por minuto, etc.)
4. **Flexibilidad**: Permite consultas personalizadas que van más allá de lo que ofrece Strava

# Análisis de Datos: Consultas sobre Actividades Deportivas

A continuación se presentan las consultas realizadas sobre los datos almacenados en InfluxDB. Cada sección incluye la justificación de la consulta, el código SQL utilizado y el análisis de los resultados.

Para comenzar, nos conectamos a la base de datos InfluxDB utilizando el cliente `influxdb_client_3` y a través de las credenciales almacenadas en variables de entorno:

```{python}
# conexión a la base de datos InfluxDB
from influxdb_client_3 import InfluxDBClient3
import os

client = InfluxDBClient3(
    host=os.getenv("INFLUX_HOST"),
    token=os.getenv("INFLUX_TOKEN"),
    org=os.getenv("INFLUX_ORG"),
    database=os.getenv("INFLUX_DATABASE")
)

# Permitir la visualización completa de los DataFrames en Pandas
import pandas as pd
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
```

## Resumen Básico de la Carrera

A través de esta primera consulta, el objetivo es obtener un resumen básico de las actividades de carrera almacenadas en la base de datos. Esto incluye métricas como la distancia total, el tiempo total, la frecuencia cardíaca media y máxima, entre otras.

Comenzamos extrayendo el número total de actividades y la lista de actividades de cada corredor:

```{python}
query = """
SELECT DISTINCT usuario, id_actividad
FROM "Run"
ORDER BY usuario
"""
table = client.query(query=query)
df = table.to_pandas()

print(f"En total, se han realizado {df.shape[0]} actividades")
print(f"Lista de actividades")
df
```

A continuación vamos a visualizar datos globales de ambos correrdores:

```{python}
query= """
SELECT usuario, 
id_actividad, 
MAX(distance) as Distancia_Total, 
ROUND(AVG(heartrate),2) as FC_Media, 
MIN(time) as Fecha_Inicio, MAX(time) as Fecha_Fin, 
date_part('epoch', MAX(time)) - date_part('epoch', MIN(time)) as duracion_segundos,
((date_part('epoch', MAX(time)) - date_part('epoch', MIN(time)))/60.0) / (MAX(distance)/1000.0) as ritmo_min_km
from "Run"
GROUP BY usuario, id_actividad
ORDER BY Distancia_Total DESC
"""
table = client.query(query=query)
df = table.to_pandas()

def decimal_a_ritmo(valor_decimal):
    if pd.isna(valor_decimal) or valor_decimal == float('inf'):
        return "0:00"
    
    minutos = int(valor_decimal) # Coge el 5 de 5.5
    segundos = (valor_decimal - minutos) * 60 # Coge el 0.5 y multiplica por 60 = 30
    
    # Formateamos para que segundos siempre tenga 2 cifras (ej. 05)
    return f"{minutos}:{int(segundos):02d}"

# 3. Aplicamos la función
df['ritmo_min_km'] = df['ritmo_min_km'].apply(decimal_a_ritmo)
df
```

Usamos date_part ('epoch') que significa, segundos totales desde 1970 hasta el mínimo y máixmo de los timestamps de nuestra BBDD.

A continuación calculamos, para cada usuario, el número de actividades, la distancia total realizada y la duración total en minutos

```{python}
query = """
SELECT  usuario, COUNT(*) as Actividades_Totales, SUM(distancia_total)/1000 as km_totales, SUM(duracion_segundos) as duracion_total
FROM (
SELECT usuario, 
id_actividad, 
MAX(distance) as Distancia_Total, 
date_part('epoch', MAX(time)) - date_part('epoch', MIN(time)) as duracion_segundos,
from "Run"
GROUP BY usuario, id_actividad
ORDER BY Distancia_Total DESC
)
GROUP BY usuario
"""
table = client.query(query=query)
df = table.to_pandas()
df

```

(aquí se han usado consultas anidadas)

## Calcular Zonas de Entrenamiento

En esta consulta, vamos a seleccionar una actividad, en este caso la del atleta `Alba`, la actividad `16843447622` y vamos a calcular el tiempo en minutos dedicados a cada zona de entrenamiento. 

Para ello, vamos a calcular la frecuencia cardiaca media durante intervalos de 10 segundos en ventanas fijas. Y tras ello, calcularemos las zonas. Para ello:

```{python}
#1. Seleccionamos la actividad donde queramos calcularlo: 
id_actividad = 16843447622

query1 = f"""
SELECT DATE_BIN (INTERVAL '10 seconds', time, TIMESTAMP '1970-01-01T00:00:00Z') as window_start,
AVG(heartrate) as FC_intervalo,
CASE
  WHEN AVG(heartrate) < 114 THEN 'Z1'
  WHEN AVG(heartrate) >= 114 AND AVG(heartrate) < 133 THEN 'Z2'
  WHEN AVG(heartrate) >= 133 AND AVG(heartrate) < 152 THEN 'Z3'
  WHEN AVG(heartrate) >= 152 AND AVG(heartrate) < 171 THEN 'Z4'
  WHEN AVG(heartrate) >= 171 THEN 'Z5'
  ELSE 'Error_Dato'
END as zonas_entrenamiento
FROM "Run"
WHERE id_actividad = {id_actividad}
GROUP BY window_start
"""

query = f"""
SELECT zonas_entrenamiento, count(*)*(10.0/60.0) as minutos_en_zona
FROM (
{query1}
)
GROUP BY zonas_entrenamiento
ORDER BY zonas_entrenamiento
"""
table = client.query(query=query)
df = table.to_pandas()

def decimal_a_minutos_segundos(valor_decimal):
    # 1. Separamos la parte entera (minutos)
    minutos = int(valor_decimal)
    
    # 2. Tomamos la parte decimal y la multiplicamos por 60 para sacar segundos
    # Usamos round() para redondear al segundo más cercano y evitar 29.9999
    segundos = int(round((valor_decimal - minutos) * 60))
    
    # 3. Ajuste por si el redondeo nos da 60 segundos
    if segundos == 60:
        minutos += 1
        segundos = 0
        
    # 4. Formateamos: :02d significa "número entero de 2 dígitos, rellena con 0 si hace falta"
    return f"{minutos:02d}min:{segundos:02d}s"


df['minutos_en_zona'] = df['minutos_en_zona'].apply(decimal_a_minutos_segundos)

df
```


## Calcular la Eficiencia Aeróbica

En esta consulta se busca extraer la eficiencia aeróbica (EF) a lo largo de la sesión. 

La eficiencia aeróbica es un indicador de rendimiento que mide la carga interna que la ha supuesto al deportista una determinada carga externa. En otras palabras, indica el esfuerzo real que ha llevado a cabo un corredor para alcanzar un resultado objetivo. 

Con los datos de los que se dispone, se divide la velocidad (carga externa) entre la frecuencia cardíaca (carga interna). Mayores cifras de eficiencia aeróbica indican un mejor estado de forma.

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG(velocity_smooth/heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS eficiencia_aerobica
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

De la consulta se extrae la siguiente gráfica:

```{python}
# Asegurar que el tiempo sea formato datetime y ordenar
df['time'] = pd.to_datetime(df['time'])
df = df.sort_values('time')

# Crear la visualización
plt.figure(figsize=(12, 6))

# Dibujar la línea de eficiencia
plt.plot(df['time'], df['eficiencia_aerobica'], 
         color='#00d1b2', linewidth=2, label='Eficiencia Aeróbica (m / latido)')

# Añadir una línea de tendencia (media móvil más larga para ver la fatiga)
plt.plot(df['time'], df['eficiencia_aerobica'].rolling(window=30).mean(), 
         color='#ff3860', linestyle='--', alpha=0.7, label='Tendencia (suavizada)')

# Personalización estética
plt.title(f'Análisis de Eficiencia Aeróbica - Actividad {id_actividad}', fontsize=14, pad=20)
plt.xlabel('Tiempo de la Actividad', fontsize=12)
plt.ylabel('Eficiencia (Velocidad/FC)', fontsize=12)
plt.grid(True, linestyle=':', alpha=0.6)
plt.legend()

# Formatear el eje X para que las fechas/horas no se amontonen
plt.gcf().autofmt_xdate()
plt.tight_layout()

plt.show()
```

**Falta interpretar gráfica**

## Comparar EF media entre actividades

Habiendo estudiado la evolución de la EF a lo largo de la sesión, en la actual consulta se ha calculado la EF media de cada sesión y se han comparado ordenando la tabla de mayor a menor valor.

```{python}
query = f"""
SELECT usuario, id_actividad, MIN (time) as fecha,
AVG(velocity_smooth/heartrate) AS eficiencia_aerobica_sesion
FROM "Run"
GROUP BY usuario, id_actividad
ORDER BY eficiencia_aerobica_sesion DESC
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

De esta consulta se puede extraer la siguiente gráfica:

```{python}
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import pandas as pd

# --- 1. Preparación de Datos ---
# Convertir a datetime si no lo está
df['fecha'] = pd.to_datetime(df['fecha'])

# Ordenar por fecha para que la línea de tiempo tenga sentido
df = df.sort_values(by='fecha')

# --- 2. Configuración de Estilo Profesional ---
sns.set_theme(style="whitegrid", context="talk")
plt.figure(figsize=(14, 7))

# Definir una paleta de colores distintiva para los usuarios
palette = sns.color_palette("husl", len(df['usuario'].unique()))

# --- 3. Graficar Puntos y Tendencias ---
# Iteramos por cada usuario para pintar sus puntos y su línea suavizada
for i, (user_name, user_data) in enumerate(df.groupby('usuario')):
    
    color = palette[i]
    
    # A. Puntos dispersos (Raw Data)
    # Los ponemos con transparencia (alpha) para que se vea el fondo pero no molesten
    sns.scatterplot(data=user_data, x='fecha', y='eficiencia_aerobica_sesion', 
                    color=color, alpha=0.3, s=50, legend=False)
    
    # B. Línea de Tendencia (Media Móvil)
    # Usamos una ventana de 5 actividades para suavizar picos. 
    # Si tienes pocas actividades, baja el 'window' a 3.
    user_data = user_data.copy() # Evitar warnings de pandas
    user_data['trend'] = user_data['eficiencia_aerobica_sesion'].rolling(window=5, min_periods=1).mean()
    
    plt.plot(user_data['fecha'], user_data['trend'], 
             color=color, linewidth=3, label=f"{user_name} (Tendencia)")

# --- 4. Formateo y Etiquetas ---

# Formatear el eje X (Fechas)
ax = plt.gca()
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y')) # Ej: Ene 2024
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1)) # Un tick cada mes (ajustar según rango de fechas)
plt.xticks(rotation=0, fontsize=12)

# Títulos y Leyendas
plt.title("Evolución de la Eficiencia Aeróbica (Velocidad / FC)", fontsize=18, weight='bold', pad=20)
plt.ylabel("Factor de Eficiencia (m/s / ppm)", fontsize=14)
plt.xlabel("", fontsize=12)

# Leyenda limpia
plt.legend(title="Usuarios", title_fontsize='13', fontsize='12', loc='upper left', frameon=True, framealpha=0.9)

# Nota explicativa pequeña
plt.figtext(0.9, 0.02, "Nota: La línea sólida representa la media móvil (tendencia).\nValores más altos indican mejor forma física.", 
            ha="right", fontsize=10, style='italic', color="#555555")

# Ajuste final
sns.despine(left=True, bottom=True)
plt.tight_layout()

plt.show()
```

**Falta interpretar la gráfica**

## Análisis de FC, Cadencia y Velocidad mediante Ventanas Móviles

Este apartado presenta un análisis de la cadencia, la velocidad y la frecuencia cardíaca mínima, máxima y medias uavizado a través de ventanas móviles de 5 segundos, lo que permitirá observar la evolución de estos parámetros a lo largo de la sesión.

Análisis de la evolución de la frecuencia cardíaca:

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG (heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_FC_media,
  MIN (heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_FC_min,
  MAX (heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_FC_max
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

Se genera una gráfica para cada medida de la frecuencia cardíaca:

```{python}
import matplotlib.pyplot as plt
import pandas as pd

# 2. Preparación de datos
df['time'] = pd.to_datetime(df['time'])

# 3. Crear la figura con 3 subgráficas (3 filas, 1 columna)
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12), sharex=True)

# Gráfica 1: FC Media
ax1.plot(df['time'], df['evolucion_fc_media'], color='red', linewidth=1.5)
ax1.set_title('Evolución Frecuencia Cardiaca Media')
ax1.set_ylabel('BPM')
ax1.grid(True, alpha=0.3)

# Gráfica 2: FC Mínima
ax2.plot(df['time'], df['evolucion_fc_min'], color='blue', linewidth=1.5)
ax2.set_title('Evolución Frecuencia Cardiaca Mínima')
ax2.set_ylabel('BPM')
ax2.grid(True, alpha=0.3)

# Gráfica 3: FC Máxima
ax3.plot(df['time'], df['evolucion_fc_max'], color='darkred', linewidth=1.5)
ax3.set_title('Evolución Frecuencia Cardiaca Máxima')
ax3.set_ylabel('BPM')
ax3.set_xlabel('Tiempo')
ax3.grid(True, alpha=0.3)

# Ajustar el formato de las fechas y el espacio entre gráficas
plt.gcf().autofmt_xdate()
plt.tight_layout()

plt.show()
```

**Falta interpretar gráficas**

Análisis de la evolución de la velocidad:

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG (velocity_smooth) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_velocidad
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

Gráfica de la evolución de la velocidad a lo largo de la sesión:

```{python}
# Convertir el tiempo a formato datetime
df['time'] = pd.to_datetime(df['time'])
plt.figure(figsize=(12, 5))

# Graficar la velocidad suavizada
plt.plot(df['time'], df['evolucion_velocidad'], color='#2ecc71', linewidth=2, label='Velocidad (Suavizada 5s)')

# Rellenar el área debajo de la curva para mejor visibilidad
plt.fill_between(df['time'], df['evolucion_velocidad'], color='#2ecc71', alpha=0.1)

# Personalización
plt.title(f'Evolución de Velocidad - Actividad {id_actividad}', fontsize=14)
plt.xlabel('Tiempo de carrera')
plt.ylabel('Velocidad (m/s)')
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()

# Formatear el eje X para que no se solapen las horas
plt.gcf().autofmt_xdate()

plt.show()
```

**Falta interpretar gráfica**

Análisis de la evolución de la cadencia durante la actividad:

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG (cadence) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_cadencia
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

Gráfica de la evolución de la velocidad:

```{python}
# Convertir a datetime para que el eje X sea temporal
df['time'] = pd.to_datetime(df['time'])
plt.figure(figsize=(12, 5))

# Graficar cadencia
plt.plot(df['time'], df['evolucion_cadencia'], color='#9b59b6', linewidth=2, label='Cadencia (SPM)')

# Añadir una línea horizontal con la cadencia media ideal (ej. 170-180)
plt.axhline(y=180, color='grey', linestyle='--', alpha=0.5, label='Objetivo (180 SPM)')

# Personalización
plt.title(f'Evolución de Cadencia - Actividad {id_actividad}', fontsize=14)
plt.xlabel('Tiempo de carrera')
plt.ylabel('Pasos por Minuto (SPM)')
plt.ylim(df['evolucion_cadencia'].min() - 10, df['evolucion_cadencia'].max() + 10) # Ajuste de zoom
plt.grid(True, linestyle=':', alpha=0.6)
plt.legend()

# Formatear el eje X
plt.gcf().autofmt_xdate()
plt.tight_layout()

plt.show()
```

**Falta interpretar gráfica**

## Ritmo ajustado a la pendiente

Para esta sección, vamos a comparar el ritmo real vs el ritmo ajustado a la pendiente:

```{python}
id_actividad = 16843447622
query1 = f"""
SELECT usuario, id_actividad, time, cadence, velocity_smooth, grade_smooth, heartrate,
((1000.0/velocity_smooth)/60.0) as ritmo_min_km, 
(
    (155.4 * POWER(grade_smooth/100.0, 5.0)) 
  - (30.4  * POWER(grade_smooth/100.0, 4.0)) 
  - (43.3  * POWER(grade_smooth/100.0, 3.0)) 
  + (46.3  * POWER(grade_smooth/100.0, 2.0)) 
  + (19.5  * (grade_smooth/100.0))
  + 3.6
) / 3.6 as ratio_esfuerzo

FROM "Run"
WHERE id_actividad = 16843447622
"""

query2 = f"""
SELECT usuario, id_actividad, time, cadence, heartrate, ritmo_min_km, 
velocity_smooth*ratio_esfuerzo as gap_velocity
FROM (
{query1}
)
"""

query= f"""
SELECT usuario, id_actividad, time, cadence, heartrate, ritmo_min_km, 
((1000.0/gap_velocity)/60.0) as ritmo_min_km_ajustado
FROM (
{query2}
)
"""
table = client.query(query=query)
df = table.to_pandas()
df

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import pandas as pd
import numpy as np

# --- 1. Preparación de Datos ---
# Asegurarnos de que 'time' es datetime (si no lo es ya)
df['time'] = pd.to_datetime(df['time'])

# Filtrar valores extremos (ruido del GPS) para que la gráfica no se rompa
# Ej: Quitamos ritmos más lentos de 20:00 min/km o más rápidos de 2:00 min/km
mask = (df['ritmo_min_km'] < 20) & (df['ritmo_min_km'] > 2)
df_clean = df.loc[mask].copy()

# Opcional: Suavizar las líneas (Rolling Mean) para que se vea más 'profesional' y menos ruidosa
window = 10  # Suavizado de 10 segundos (ajustar según gusto)
df_clean['ritmo_smooth'] = df_clean['ritmo_min_km'].rolling(window, center=True).mean()
df_clean['gap_smooth'] = df_clean['ritmo_min_km_ajustado'].rolling(window, center=True).mean()

# --- 2. Configuración de Estilo "Profesional" ---
sns.set_theme(style="whitegrid", context="talk") # Fondo limpio con rejilla suave
plt.figure(figsize=(14, 6))

# Colores corporativos/profesionales
color_real = "#95a5a6"  # Gris (Ritmo Real - contexto)
color_gap = "#e74c3c"   # Rojo Intenso (GAP - dato destacado)

# --- 3. Graficado ---
# Ritmo Real (Fondo)
plt.plot(df_clean['time'], df_clean['ritmo_smooth'], 
         label='Ritmo Real', color=color_real, alpha=0.6, linewidth=1.5)

# GAP (Principal)
plt.plot(df_clean['time'], df_clean['gap_smooth'], 
         label='Ritmo Ajustado (GAP)', color=color_gap, linewidth=2.5)

# Rellenar la diferencia para resaltar el esfuerzo en subidas
plt.fill_between(df_clean['time'], df_clean['ritmo_smooth'], df_clean['gap_smooth'], 
                 where=(df_clean['gap_smooth'] < df_clean['ritmo_smooth']), # Donde GAP es más rápido (subida)
                 color=color_gap, alpha=0.1, interpolate=True)

# --- 4. Formateo de Ejes ---

# Eje Y Invertido (Más rápido arriba)
plt.gca().invert_yaxis()

# Formatear Eje Y para mostrar minutos:segundos en lugar de decimales
def decimal_to_mmss(x, pos):
    mins = int(x)
    secs = int((x - mins) * 60)
    return f"{mins}:{secs:02d}"

plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(decimal_to_mmss))

# Formatear Eje X (Tiempo)
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))

# Títulos y Leyenda
plt.title("Comparativa de Esfuerzo: Ritmo Real vs. GAP", fontsize=16, pad=20, weight='bold')
plt.ylabel("Ritmo (min/km)", fontsize=12)
plt.xlabel("Hora", fontsize=12)
plt.legend(frameon=True, loc='upper right')

# Límites limpios (Opcional: Ajustar según tus datos)
# plt.ylim(7, 3) # Ejemplo: mostrar solo entre 7:00 y 3:00 min/km

sns.despine(left=True, bottom=True) # Quitar bordes innecesarios
plt.tight_layout()
plt.show()

```

## Cálculo de la fc máxima observada

En este apartado vamos a calcular la frecuencia cardiaca máxima observada. Para ello, vamos a definir ventanas móviles de 10 segundos para calcularlo. La motivación para no usar ventanas fijas es que puedes estar cortando un esfuerzo submáximo que se da del segundo 7 al 13 en dos ventanas distintas, la 6-10 y la 11-15. 

```{python}
query1 = """
SELECT time, usuario, id_actividad, AVG(heartrate) OVER (
  PARTITION BY usuario, id_actividad
  ORDER BY time RANGE INTERVAL '10 seconds' PRECEDING
) as pulsaciones_media_10s

from "Run"
ORDER BY usuario, id_actividad
"""

query = f"""
SELECT usuario, id_actividad, MAX(pulsaciones_media_10s) as FC_MAX
FROM ({query1})
GROUP BY usuario, id_actividad
ORDER BY usuario, FC_MAX DESC
"""

table = client.query(query=query)
df = table.to_pandas()
df
```

## Mapa de actividades

Podemos visualizar el recorrido de una actividad. Para ello: 

```{python}
# Importamos folium para hacer el mapa:
import folium
import branca.colormap as cm

# Recogemos la actividad de la BBDD:
id_actividad = 16967764621

# Seleccionamos todo de esa actividad:
query = f"""
SELECT *
from "Run"
WHERE id_actividad = {id_actividad}
"""
table = client.query(query = query)
df = table.to_pandas()

# Lista de coordenadas:
ruta_coords = list(zip(df['latitude'], df['longitude']))

# Calculamos el centro del mapa (la media de tus coordenadas)
centro_mapa = [df['latitude'].mean(), df['longitude'].mean()]

# Creamos el mapa base. zoom_start depende de lo larga que sea la ruta
m = folium.Map(location=centro_mapa, zoom_start=14, tiles='cartodbpositron')

# 2. Crear la Escala de Colores (El gradiente estilo Strava)
colormap = cm.LinearColormap(colors=['red', 'yellow', 'green'],
                             vmin=df['velocity_smooth'].min(),
                             vmax=df['velocity_smooth'].max(), 
                             caption=f'Intensidad: Velocity_smooth')


# 3. Dibujar la ruta coloreada
# Iteramos por los puntos de la ruta, de dos en dos, para crear segmentos
for i in range(len(ruta_coords) - 1):
    punto_A = ruta_coords[i]
    punto_B = ruta_coords[i+1]
    
    # El valor para colorear este segmento es el del punto inicial A
    valor_actual = df.iloc[i]['velocity_smooth']
    
    # Obtenemos el color correspondiente a ese valor
    color_segmento = colormap(valor_actual)
    
    # Dibujamos la pequeña línea que une A con B
    folium.PolyLine(
        locations=[punto_A, punto_B],
        color=color_segmento,
        weight=5,         # Grosor de la línea (Strava usa líneas gruesas)
        opacity=0.8       # Un poco de transparencia queda elegante
    ).add_to(m)


# 4. Añadir detalles finales "Pro"
# Añadir la leyenda de colores al mapa
m.add_child(colormap)

# Marcador de Inicio (Icono verde de "play")
folium.Marker(
    location=ruta_coords[0],
    popup="Inicio",
    icon=folium.Icon(color='green', icon='play', prefix='fa') # fa = fontawesome icons
).add_to(m)

# Marcador de Fin (Icono rojo de "stop" o bandera)
folium.Marker(
    location=ruta_coords[-1],
    popup="Fin",
    icon=folium.Icon(color='red', icon='flag', prefix='fa')
).add_to(m)

# Añadir control para cambiar a vista satélite
folium.TileLayer('esri.worldimagery', name='Satélite').add_to(m)
folium.LayerControl().add_to(m)
m
```

# Cerrar la conexión a InfluxDB

```{python}
client.close()
```