---
title: "Práctica Final. Memoria de Consultas sobre Datos de Strava en InfluxDB"
author:
  - Alba Martínez de la Hermosa
  - Alonso González Romero
date: today
format:
  html:
    page-layout: full  
    css: style.css
    embed-resources: true
    plotly-connected: true
    toc: true
    toc-depth: 3
    number-sections: true
lang: es
abstract: |
  En esta memoria se documentan las consultas realizadas sobre los datos de actividades de Strava, almacenados en una base de datos InfluxDB. Se incluyen descripciones de las consultas, el código utilizado, los resultados obtenidos y visualizaciones relevantes.
---

# Introducción

En el contexto actual del análisis deportivo, la capacidad de centralizar, procesar y explotar datos biométricos y de posicionamiento es fundamental para evaluar el rendimiento. Este proyecto tiene como objetivo principal la creación de una arquitectura de datos escalable para el almacenamiento y análisis de actividades deportivas de carrera.

El proyecto aborda la problemática de la dispersión de datos en plataformas de terceros (como Strava) mediante la implementación de un proceso **ETL (Extract, Transform, Load)** propio. Hemos diseñado un sistema que permite a dos usuarios diferentes (Alba y Alonso) extraer sus actividades con granulaidad de segundo (series temporales), normalizarlas y almacenarlas en una base de datos **InfluxDB**. Esto nos permite superar las limitaciones de análisis de las aplicaciones comerciales y realizar consultas personalizadas sobre variables críticas como la frecuencia cardíaca, la potencia estimada, la velocidad y la pendiente.

# Arquitectura del Sistema y Proceso ETL

## Extracción de Datos desde la API de Strava

El proceso de extracción de datos comienza con la autenticación en la **API de Strava** mediante el protocolo OAuth 2.0. Para ello, cada usuario (Alba y Alonso) dispone de credenciales únicas almacenadas de forma segura en un archivo `.env` (no versionado en el repositorio). Este archivo contiene:

- **Client ID**: Identificador de la aplicación registrada en Strava
- **Client Secret**: Clave secreta de la aplicación
- **Refresh Token**: Token de larga duración que permite obtener access tokens sin intervención manual

El script principal (`main.py`) utiliza la librería `python-dotenv` para cargar estas variables de entorno de forma segura, evitando hardcodear credenciales sensibles en el código fuente.

### Flujo de Autenticación y Obtención de Tokens

La función `obtener_token_acceso()` implementa el flujo de renovación de tokens:

1. Realiza una petición POST al endpoint `https://www.strava.com/oauth/token`
2. Envía el refresh token junto con las credenciales de la aplicación
3. Recibe un nuevo access token válido por 6 horas
4. Este access token se utiliza para todas las peticiones posteriores a la API

```python
def obtener_token_acceso(client_id, client_secret, refresh_token, usuario):
    auth_url = "https://www.strava.com/oauth/token"
    payload = {
        'client_id': client_id,
        'client_secret': client_secret,
        'refresh_token': refresh_token,
        'grant_type': 'refresh_token',
        'f': 'json'
    }
    res = requests.post(auth_url, data=payload, verify=False)
    return res.json()['access_token']
```

### Descarga de Datos de Actividades (Streams)

Una vez autenticados, utilizamos el endpoint de **streams** de Strava para obtener datos de alta granularidad (segundo a segundo) de cada actividad. La función `descargar_datos_actividad()` solicita todos los streams disponibles:

- **time**: Tiempo transcurrido desde el inicio (segundos)
- **distance**: Distancia acumulada (metros)
- **latlng**: Coordenadas GPS (latitud, longitud)
- **altitude**: Altitud (metros)
- **velocity_smooth**: Velocidad suavizada (m/s)
- **heartrate**: Frecuencia cardíaca (bpm)
- **cadence**: Cadencia de pasos o pedaladas (rpm/spm)
- **watts**: Potencia (solo si disponible)
- **temp**: Temperatura
- **grade_smooth**: Pendiente suavizada (%)

El proceso de transformación incluye:

1. **Separación de coordenadas GPS**: El stream `latlng` contiene arrays de [latitud, longitud] que se separan en columnas independientes
2. **Cálculo de timestamps absolutos**: Los valores de `time` (relativos al inicio) se convierten a timestamps absolutos sumándolos a la fecha de inicio de la actividad
3. **Creación de DataFrame**: Todos los streams se consolidan en un DataFrame de pandas

```python
# Obtener fecha de inicio de la actividad
url_act = f"https://www.strava.com/api/v3/activities/{activity_id}"
resp_act = requests.get(url_act, headers=headers).json()
start_date = datetime.strptime(resp_act['start_date'], "%Y-%m-%dT%H:%M:%SZ")

# Calcular timestamps reales
df['timestamp_real'] = df['time'].apply(lambda x: start_date + timedelta(seconds=x))
```

## Transformación y Preparación de Datos

Antes de cargar los datos en InfluxDB, se realiza una transformación crítica para enriquecer el dataset con metadatos necesarios para las consultas posteriores. La función `preparar_csv_para_influx()` añade las siguientes columnas:

- **measurement**: Tipo de actividad (Run, Cycling, Swimming) - se utilizará como nombre de la tabla en InfluxDB
- **usuario**: Identificador del atleta (Alba o Alonso)
- **id_actividad**: ID único de la actividad en Strava
- **tipo_actividad**: Clasificación de la actividad

Estas columnas se configurarán como **tags** en InfluxDB, lo que permite realizar consultas eficientes filtradas por usuario o actividad.

## Variables Disponibles en el Dataset

El dataset final contiene las siguientes variables para cada segundo de la actividad:

| Variable | Descripción | Unidad | Tipo |
|----------|-------------|--------|------|
| `timestamp_real` | Timestamp absoluto | DateTime | Field |
| `time` | Tiempo relativo desde inicio | segundos | Field |
| `distance` | Distancia acumulada | metros | Field |
| `latitude` | Latitud GPS | grados | Field |
| `longitude` | Longitud GPS | grados | Field |
| `altitude` | Altitud | metros | Field |
| `velocity_smooth` | Velocidad suavizada | m/s | Field |
| `heartrate` | Frecuencia cardíaca | bpm | Field |
| `cadence` | Cadencia | spm/rpm | Field |
| `watts` | Potencia (si disponible) | W | Field |
| `temp` | Temperatura | °C | Field |
| `grade_smooth` | Pendiente | % | Field |
| `usuario` | Identificador del usuario | - | Tag |
| `id_actividad` | ID de la actividad | - | Tag |
| `tipo_actividad` | Tipo de actividad | - | Tag |

## Carga en InfluxDB

InfluxDB es una base de datos de series temporales optimizada para datos con timestamps y alta frecuencia de escritura. Utilizamos **InfluxDB Cloud (v3)** con el cliente `influxdb_client_3`.

### Configuración de la Conexión

La conexión a InfluxDB requiere:

- **Host**: URL del servidor InfluxDB Cloud
- **Token**: Token de autenticación con permisos de escritura
- **Organización**: Nombre de la organización en InfluxDB
- **Database**: Nombre del bucket/database donde se almacenarán los datos

Todas estas credenciales se almacenan en variables de entorno por seguridad.

### Proceso de Carga

La función `subir_a_influxdb()` realiza la carga utilizando el método `write_file()`:

```python
client = InfluxDBClient3(host=host, token=token, org=org, database=database)

client.write_file(
    file=archivo_csv,
    tag_columns=["measurement", "usuario", "id_actividad", "tipo_actividad"],
    timestamp_column="timestamp_real",
    data_format="csv"
)
```

**Puntos clave del proceso:**

- Se especifican las columnas que funcionarán como **tags** (índices) para optimizar las consultas
- Se indica la columna de timestamp para el eje temporal
- El measurement (tipo de actividad) se usa como nombre de la tabla

### Ventajas de esta Arquitectura

1. **Escalabilidad**: InfluxDB está optimizado para series temporales con millones de puntos
2. **Consultas eficientes**: Los tags permiten filtrar rápidamente por usuario o actividad
3. **Downsampling**: Soporte nativo para agregaciones temporales (medias móviles, resúmenes por minuto, etc.)
4. **Flexibilidad**: Permite consultas personalizadas que van más allá de lo que ofrece Strava

# Análisis de Datos: Consultas sobre Actividades Deportivas

A continuación se presentan las consultas realizadas sobre los datos almacenados en InfluxDB. Cada sección incluye la justificación de la consulta, el código SQL utilizado y el análisis de los resultados.

Para comenzar, nos conectamos a la base de datos InfluxDB utilizando el cliente `influxdb_client_3` y a través de las credenciales almacenadas en variables de entorno:

```{python}
# conexión a la base de datos InfluxDB
from influxdb_client_3 import InfluxDBClient3
import os

client = InfluxDBClient3(
    host=os.getenv("INFLUX_HOST"),
    token=os.getenv("INFLUX_TOKEN"),
    org=os.getenv("INFLUX_ORG"),
    database=os.getenv("INFLUX_DATABASE")
)

# Permitir la visualización completa de los DataFrames en Pandas
import pandas as pd
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
```

## Resumen Básico de la Carrera

A través de esta primera consulta, el objetivo es obtener un resumen básico de las actividades de carrera almacenadas en la base de datos. Esto incluye métricas como la distancia total, el tiempo total, la frecuencia cardíaca media y máxima, entre otras.

Comenzamos extrayendo el número total de actividades y la lista de actividades de cada corredor:

```{python}
query = """
SELECT DISTINCT usuario, id_actividad
FROM "Run"
ORDER BY usuario
"""
table = client.query(query=query)
df = table.to_pandas()

print(f"En total, se han realizado {df.shape[0]} actividades")
print(f"Lista de actividades")
df
```

A continuación vamos a visualizar datos globales de ambos correrdores:

```{python}
query= """
SELECT usuario, 
id_actividad, 
MAX(distance) as Distancia_Total, 
ROUND(AVG(heartrate),2) as FC_Media, 
MIN(time) as Fecha_Inicio, MAX(time) as Fecha_Fin, 
date_part('epoch', MAX(time)) - date_part('epoch', MIN(time)) as duracion_segundos,
((date_part('epoch', MAX(time)) - date_part('epoch', MIN(time)))/60.0) / (MAX(distance)/1000.0) as ritmo_min_km
from "Run"
GROUP BY usuario, id_actividad
ORDER BY Distancia_Total DESC
"""
table = client.query(query=query)
df = table.to_pandas()

def decimal_a_ritmo(valor_decimal):
    if pd.isna(valor_decimal) or valor_decimal == float('inf'):
        return "0:00"
    
    minutos = int(valor_decimal) # Coge el 5 de 5.5
    segundos = (valor_decimal - minutos) * 60 # Coge el 0.5 y multiplica por 60 = 30
    
    # Formateamos para que segundos siempre tenga 2 cifras (ej. 05)
    return f"{minutos}:{int(segundos):02d}"

# 3. Aplicamos la función
df['ritmo_min_km'] = df['ritmo_min_km'].apply(decimal_a_ritmo)
df
```

Usamos date_part ('epoch') que significa, segundos totales desde 1970 hasta el mínimo y máixmo de los timestamps de nuestra BBDD.

A continuación calculamos, para cada usuario, el número de actividades, la distancia total realizada y la duración total en minutos

```{python}
query = """
SELECT  usuario, COUNT(*) as Actividades_Totales, SUM(distancia_total)/1000 as km_totales, SUM(duracion_segundos) as duracion_total
FROM (
SELECT usuario, 
id_actividad, 
MAX(distance) as Distancia_Total, 
date_part('epoch', MAX(time)) - date_part('epoch', MIN(time)) as duracion_segundos,
from "Run"
GROUP BY usuario, id_actividad
ORDER BY Distancia_Total DESC
)
GROUP BY usuario
"""
table = client.query(query=query)
df = table.to_pandas()
df

```

(aquí se han usado consultas anidadas)

## Calcular Zonas de Entrenamiento
Aquí habría que: 
1. Hacer una tabla con una ventana de 5/10 segundos y calcular la frecuencia suavizada y luego agrupar, con un count (por tener 1s por cada segundo de actividad) los segundos en cada zona :)

VENTANA FIJA

```{python}

#1. Seleccionamos una actividad donde queramos calcularlo: 
id_actividad = 16843447622

query = f"""
SELECT * 
FROM "Run"
WHERE id_actividad = {id_actividad}
"""
table = client.query(query=query)
df = table.to_pandas()
df

```

## Calcular la Eficiencia Aeróbica

En esta consulta se busca extraer la eficiencia aeróbica (EF) a lo largo de la sesión. 

La eficiencia aeróbica es un indicador de rendimiento que mide la carga interna que la ha supuesto al deportista una determinada carga externa. En otras palabras, indica el esfuerzo real que ha llevado a cabo un corredor para alcanzar un resultado objetivo. 

Con los datos de los que se dispone, se divide la velocidad (carga externa) entre la frecuencia cardíaca (carga interna). Mayores cifras de eficiencia aeróbica indican un mejor estado de forma.

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG(velocity_smooth/heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS eficiencia_aerobica
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

De la consulta se extrae la siguiente gráfica:

```{python}
# Asegurar que el tiempo sea formato datetime y ordenar
df['time'] = pd.to_datetime(df['time'])
df = df.sort_values('time')

# Crear la visualización
plt.figure(figsize=(12, 6))

# Dibujar la línea de eficiencia
plt.plot(df['time'], df['eficiencia_aerobica'], 
         color='#00d1b2', linewidth=2, label='Eficiencia Aeróbica (m / latido)')

# Añadir una línea de tendencia (media móvil más larga para ver la fatiga)
plt.plot(df['time'], df['eficiencia_aerobica'].rolling(window=30).mean(), 
         color='#ff3860', linestyle='--', alpha=0.7, label='Tendencia (suavizada)')

# Personalización estética
plt.title(f'Análisis de Eficiencia Aeróbica - Actividad {id_actividad}', fontsize=14, pad=20)
plt.xlabel('Tiempo de la Actividad', fontsize=12)
plt.ylabel('Eficiencia (Velocidad/FC)', fontsize=12)
plt.grid(True, linestyle=':', alpha=0.6)
plt.legend()

# Formatear el eje X para que las fechas/horas no se amontonen
plt.gcf().autofmt_xdate()
plt.tight_layout()

plt.show()
```

**Falta interpretar gráfica**

## Comparar EF media entre actividades

Habiendo estudiado la evolución de la EF a lo largo de la sesión, en la actual consulta se ha calculado la EF media de cada sesión y se han comparado ordenando la tabla de mayor a menor valor.

```{python}
query = f"""
SELECT usuario, id_actividad, MIN (time) as fecha,
AVG(velocity_smooth/heartrate) AS eficiencia_aerobica_sesion
FROM "Run"
GROUP BY usuario, id_actividad
ORDER BY eficiencia_aerobica_sesion DESC
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

De esta consulta se puede extraer la siguiente gráfica:

```{python}
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import pandas as pd

# --- 1. Preparación de Datos ---
# Convertir a datetime si no lo está
df['fecha'] = pd.to_datetime(df['fecha'])

# Ordenar por fecha para que la línea de tiempo tenga sentido
df = df.sort_values(by='fecha')

# --- 2. Configuración de Estilo Profesional ---
sns.set_theme(style="whitegrid", context="talk")
plt.figure(figsize=(14, 7))

# Definir una paleta de colores distintiva para los usuarios
palette = sns.color_palette("husl", len(df['usuario'].unique()))

# --- 3. Graficar Puntos y Tendencias ---
# Iteramos por cada usuario para pintar sus puntos y su línea suavizada
for i, (user_name, user_data) in enumerate(df.groupby('usuario')):
    
    color = palette[i]
    
    # A. Puntos dispersos (Raw Data)
    # Los ponemos con transparencia (alpha) para que se vea el fondo pero no molesten
    sns.scatterplot(data=user_data, x='fecha', y='eficiencia_aerobica_sesion', 
                    color=color, alpha=0.3, s=50, legend=False)
    
    # B. Línea de Tendencia (Media Móvil)
    # Usamos una ventana de 5 actividades para suavizar picos. 
    # Si tienes pocas actividades, baja el 'window' a 3.
    user_data = user_data.copy() # Evitar warnings de pandas
    user_data['trend'] = user_data['eficiencia_aerobica_sesion'].rolling(window=5, min_periods=1).mean()
    
    plt.plot(user_data['fecha'], user_data['trend'], 
             color=color, linewidth=3, label=f"{user_name} (Tendencia)")

# --- 4. Formateo y Etiquetas ---

# Formatear el eje X (Fechas)
ax = plt.gca()
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y')) # Ej: Ene 2024
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1)) # Un tick cada mes (ajustar según rango de fechas)
plt.xticks(rotation=0, fontsize=12)

# Títulos y Leyendas
plt.title("Evolución de la Eficiencia Aeróbica (Velocidad / FC)", fontsize=18, weight='bold', pad=20)
plt.ylabel("Factor de Eficiencia (m/s / ppm)", fontsize=14)
plt.xlabel("", fontsize=12)

# Leyenda limpia
plt.legend(title="Usuarios", title_fontsize='13', fontsize='12', loc='upper left', frameon=True, framealpha=0.9)

# Nota explicativa pequeña
plt.figtext(0.9, 0.02, "Nota: La línea sólida representa la media móvil (tendencia).\nValores más altos indican mejor forma física.", 
            ha="right", fontsize=10, style='italic', color="#555555")

# Ajuste final
sns.despine(left=True, bottom=True)
plt.tight_layout()

plt.show()
```

**Falta interpretar la gráfica**

## Análisis de FC, Cadencia y Velocidad mediante Ventanas Móviles

Este apartado presenta un análisis de la cadencia, la velocidad y la frecuencia cardíaca mínima, máxima y medias uavizado a través de ventanas móviles de 5 segundos, lo que permitirá observar la evolución de estos parámetros a lo largo de la sesión.

Análisis de la evolución de la frecuencia cardíaca:

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG (heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_FC_media,
  MIN (heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_FC_min,
  MAX (heartrate) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_FC_max
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

Se genera una gráfica para cada medida de la frecuencia cardíaca:

```{python}
import matplotlib.pyplot as plt
import pandas as pd

# 2. Preparación de datos
df['time'] = pd.to_datetime(df['time'])

# 3. Crear la figura con 3 subgráficas (3 filas, 1 columna)
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12), sharex=True)

# Gráfica 1: FC Media
ax1.plot(df['time'], df['evolucion_fc_media'], color='red', linewidth=1.5)
ax1.set_title('Evolución Frecuencia Cardiaca Media')
ax1.set_ylabel('BPM')
ax1.grid(True, alpha=0.3)

# Gráfica 2: FC Mínima
ax2.plot(df['time'], df['evolucion_fc_min'], color='blue', linewidth=1.5)
ax2.set_title('Evolución Frecuencia Cardiaca Mínima')
ax2.set_ylabel('BPM')
ax2.grid(True, alpha=0.3)

# Gráfica 3: FC Máxima
ax3.plot(df['time'], df['evolucion_fc_max'], color='darkred', linewidth=1.5)
ax3.set_title('Evolución Frecuencia Cardiaca Máxima')
ax3.set_ylabel('BPM')
ax3.set_xlabel('Tiempo')
ax3.grid(True, alpha=0.3)

# Ajustar el formato de las fechas y el espacio entre gráficas
plt.gcf().autofmt_xdate()
plt.tight_layout()

plt.show()
```

**Falta interpretar gráficas**

Análisis de la evolución de la velocidad:

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG (velocity_smooth) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_velocidad
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

Gráfica de la evolución de la velocidad a lo largo de la sesión:

```{python}
# Convertir el tiempo a formato datetime
df['time'] = pd.to_datetime(df['time'])
plt.figure(figsize=(12, 5))

# Graficar la velocidad suavizada
plt.plot(df['time'], df['evolucion_velocidad'], color='#2ecc71', linewidth=2, label='Velocidad (Suavizada 5s)')

# Rellenar el área debajo de la curva para mejor visibilidad
plt.fill_between(df['time'], df['evolucion_velocidad'], color='#2ecc71', alpha=0.1)

# Personalización
plt.title(f'Evolución de Velocidad - Actividad {id_actividad}', fontsize=14)
plt.xlabel('Tiempo de carrera')
plt.ylabel('Velocidad (m/s)')
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()

# Formatear el eje X para que no se solapen las horas
plt.gcf().autofmt_xdate()

plt.show()
```

**Falta interpretar gráfica**

Análisis de la evolución de la cadencia durante la actividad:

```{python}
id_actividad = 16835006867

query = f"""
SELECT usuario, id_actividad, time,
  AVG (cadence) OVER (
    PARTITION BY usuario, id_actividad
    ORDER BY time
    RANGE INTERVAL '5 seconds' PRECEDING
  ) AS evolucion_cadencia
FROM "Run"
WHERE id_actividad = {id_actividad}
ORDER BY usuario, id_actividad 
"""
table = client.query(query=query)
df = table.to_pandas()
df
```

Gráfica de la evolución de la velocidad:

```{python}
# Convertir a datetime para que el eje X sea temporal
df['time'] = pd.to_datetime(df['time'])
plt.figure(figsize=(12, 5))

# Graficar cadencia
plt.plot(df['time'], df['evolucion_cadencia'], color='#9b59b6', linewidth=2, label='Cadencia (SPM)')

# Añadir una línea horizontal con la cadencia media ideal (ej. 170-180)
plt.axhline(y=180, color='grey', linestyle='--', alpha=0.5, label='Objetivo (180 SPM)')

# Personalización
plt.title(f'Evolución de Cadencia - Actividad {id_actividad}', fontsize=14)
plt.xlabel('Tiempo de carrera')
plt.ylabel('Pasos por Minuto (SPM)')
plt.ylim(df['evolucion_cadencia'].min() - 10, df['evolucion_cadencia'].max() + 10) # Ajuste de zoom
plt.grid(True, linestyle=':', alpha=0.6)
plt.legend()

# Formatear el eje X
plt.gcf().autofmt_xdate()
plt.tight_layout()

plt.show()
```

**Falta interpretar gráfica**

## Ritmo ajustado a la pendiente
Usar grade_smooth

Ritmos totales, mínimo y máximo por un lado
Gráfica del ritmo ajustado a lo largo de un entreno

## Cálculo de la fc máxima observada
O estimación, o cálculo del intervalo de X segundos donde se haya alcanzado la fc máxima


# Cerrar la conexión a InfluxDB

```{python}
client.close()
```